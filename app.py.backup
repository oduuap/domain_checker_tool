#!/usr/bin/env python3
"""
DOMAIN FINDER WEB APP
Web interface ƒë·ªÉ t√¨m expired domains v·ªõi traffic
"""

from flask import Flask, render_template, request, jsonify, send_file, Response
from flask_cors import CORS
import json
import time
import os
from datetime import datetime
from threading import Thread, Lock
from concurrent.futures import ThreadPoolExecutor, as_completed
import queue
import whois
import dns.resolver
import requests
import re
from typing import Dict, List, Optional
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill, Alignment
from openpyxl.utils import get_column_letter
from bs4 import BeautifulSoup
from urllib.parse import quote
from keyword_database import KeywordGenerator

app = Flask(__name__)
CORS(app)

# Initialize keyword generator
keyword_gen = KeywordGenerator()

# API Keys
RAPIDAPI_KEY = "3267466f8dmshf9b9f3bb87d2afcp10c10bjsnccecb46bc96a"
C99_API_KEY = "POM2S-E8ZC6-7KFVA-VH8TP"

# Global variables cho progress tracking
search_progress = {
    'status': 'idle',
    'current': 0,
    'total': 0,
    'message': '',
    'domains_found': [],
    'current_domain': ''
}

class DomainChecker:
    def __init__(self, rapidapi_key=None, c99_api_key=None):
        self.rapidapi_key = rapidapi_key
        self.c99_api_key = c99_api_key

    def check_domain_availability(self, domain: str) -> Dict:
        """Ki·ªÉm tra domain c√≥ available kh√¥ng"""
        result = {
            'domain': domain,
            'available': None,
            'creation_date': None,
            'age_years': None,
            'registrar': None,
            'status': None
        }

        try:
            w = whois.whois(domain)

            if w.domain_name:
                result['available'] = False
                result['registrar'] = w.registrar
                result['status'] = 'Registered'

                creation_date = w.creation_date
                if isinstance(creation_date, list):
                    creation_date = creation_date[0]

                if creation_date:
                    result['creation_date'] = creation_date.strftime('%Y-%m-%d') if isinstance(creation_date, datetime) else str(creation_date)
                    if isinstance(creation_date, datetime):
                        creation_date_naive = creation_date.replace(tzinfo=None) if creation_date.tzinfo else creation_date
                        age = datetime.now() - creation_date_naive
                        result['age_years'] = round(age.days / 365.25, 1)
            else:
                result['available'] = True

        except Exception as e:
            error_msg = str(e).lower()
            if 'no match' in error_msg or 'not found' in error_msg or 'no data' in error_msg:
                result['available'] = True
                result['status'] = 'Available'

        return result

    def check_wayback_history(self, domain: str) -> Dict:
        """Ki·ªÉm tra l·ªãch s·ª≠ tr√™n Wayback Machine"""
        result = {
            'snapshot_count': 0,
            'first_archive': None,
            'last_archive': None,
            'age_years': 0,
            'has_history': False
        }

        try:
            url = f"http://web.archive.org/cdx/search/cdx?url={domain}&output=json&limit=10000"
            response = requests.get(url, timeout=15)

            if response.status_code == 200:
                data = response.json()

                if len(data) > 1:
                    result['snapshot_count'] = len(data) - 1
                    result['has_history'] = True

                    first_timestamp = data[1][1]
                    last_timestamp = data[-1][1]

                    result['first_archive'] = first_timestamp[:8]
                    result['last_archive'] = last_timestamp[:8]

                    first_year = int(first_timestamp[:4])
                    current_year = datetime.now().year
                    result['age_years'] = current_year - first_year

        except Exception as e:
            pass

        return result

    def check_seo_metrics_rapidapi(self, domain: str) -> Dict:
        """Ki·ªÉm tra DR/UR/SEO metrics qua RapidAPI"""
        result = {
            'domain_rating': 0,
            'url_rating': 0,
            'organic_traffic': 0,
            'backlinks': 0,
            'referring_domains': 0,
            'has_seo_value': False
        }

        if not self.rapidapi_key:
            return result

        try:
            url = "https://seo-api-dr-rd-rank-keywords-backlinks.p.rapidapi.com/url-metrics"

            headers = {
                'x-rapidapi-host': 'seo-api-dr-rd-rank-keywords-backlinks.p.rapidapi.com',
                'x-rapidapi-key': self.rapidapi_key
            }

            params = {'url': f'https://{domain}'}

            response = requests.get(url, headers=headers, params=params, timeout=15)

            if response.status_code == 200:
                data = response.json()

                # Parse ƒê√öNG structure c·ªßa RapidAPI response
                if data.get('success') and 'data' in data:
                    api_data = data['data']

                    # L·∫•y domain metrics
                    domain_metrics = api_data.get('domain', {})
                    page_metrics = api_data.get('page', {})

                    result['domain_rating'] = domain_metrics.get('domainRating', 0) or 0
                    result['url_rating'] = page_metrics.get('urlRating', 0) or 0
                    # GI·ªÆ TRAFFIC D·∫†NG FLOAT ƒë·ªÉ kh√¥ng m·∫•t traffic nh·ªè (< 1)
                    result['organic_traffic'] = float(domain_metrics.get('trafficVol', 0) or 0)
                    result['backlinks'] = domain_metrics.get('backlinks', 0) or 0
                    result['referring_domains'] = domain_metrics.get('refDomains', 0) or 0
                    result['has_seo_value'] = result['domain_rating'] > 0 or result['organic_traffic'] > 0

        except Exception as e:
            pass

        return result

    def check_registrar_availability(self, domain: str) -> Dict:
        """Ki·ªÉm tra domain c√≥ mua ƒë∆∞·ª£c kh√¥ng t·∫°i Namecheap"""
        result = {
            'purchasable': False,
            'price': None,
            'url': None,
            'is_premium': False
        }

        try:
            search_url = f"https://www.namecheap.com/domains/registration/results/?domain={domain}"
            result['url'] = search_url

            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
            }

            response = requests.get(search_url, headers=headers, timeout=15)

            if response.status_code == 200:
                content = response.text.lower()

                if 'available' in content and 'add to cart' in content:
                    result['purchasable'] = True

                    price_match = re.search(r'\$(\d+\.\d+)', response.text)
                    if price_match:
                        result['price'] = f"${price_match.group(1)}"

                if 'premium' in content:
                    result['is_premium'] = True

            time.sleep(1)

        except Exception as e:
            pass

        return result

    def generate_keyword_variations(self, keyword: str, max_variations: int = 20) -> List[str]:
        """T·∫°o variations t·ª´ keyword"""
        variations = [keyword]

        suffixes = ['hub', 'app', 'pro', 'web', 'net', 'zone', 'spot', 'land', 'world']
        prefixes = ['my', 'get', 'the', 'top', 'best', 'new', 'hot']

        for suffix in suffixes:
            variations.append(f"{keyword}{suffix}")

        for prefix in prefixes:
            variations.append(f"{prefix}{keyword}")

        return list(dict.fromkeys(variations))[:max_variations]

    def fetch_subdomains_c99_api(self, domain: str) -> List[str]:
        """
        L·∫•y subdomains qua C99 API - CH√çNH X√ÅC & NHANH

        Args:
            domain: TLD (vd: 'sa.com', 'ca.com')

        Returns:
            List subdomains
        """
        subdomains = []

        if not self.c99_api_key:
            return subdomains

        try:
            # C99 Subdomain Finder API
            url = "https://api.c99.nl/subdomainfinder"

            params = {
                'key': self.c99_api_key,
                'domain': domain,
                'json': 'true'
            }

            print(f"  üì° Calling C99 API for {domain}...", end=' ')

            response = requests.get(url, params=params, timeout=30)

            if response.status_code == 200:
                data = response.json()

                # Check response success
                if data.get('success') == True or data.get('success') == 1:
                    # Parse subdomains t·ª´ response
                    if 'subdomains' in data:
                        subdomains = data['subdomains']
                    elif 'result' in data:
                        result = data['result']
                        if isinstance(result, list):
                            subdomains = result
                        elif isinstance(result, dict) and 'subdomains' in result:
                            subdomains = result['subdomains']

                    print(f"‚úì Found {len(subdomains)} subdomains")

                else:
                    error = data.get('error', 'Unknown error')
                    print(f"‚úó API Error: {error}")

            else:
                print(f"‚úó HTTP {response.status_code}")

        except Exception as e:
            print(f"‚úó Error: {str(e)[:50]}")

        return subdomains

    def fetch_domains_from_c99(self, tld: str) -> List[str]:
        """
        L·∫•y danh s√°ch domains t·ª´ c99.nl API

        Args:
            tld: TLD c·∫ßn l·∫•y (vd: 'ca.com', 'sa.com', 'ru.com')

        Returns:
            List domains
        """
        domains = []

        # Try C99 API
        if self.c99_api_key:
            print(f"\nüì° Fetching domains from C99 API for {tld}...")
            raw_domains = self.fetch_subdomains_c99_api(tld)

            if raw_domains:
                # Parse domains - handle multiple formats
                parsed_domains = []

                for item in raw_domains:
                    try:
                        if isinstance(item, str):
                            # Format 1: ["domain.com", "domain2.com"]
                            parsed_domains.append(item.lower().strip())
                        elif isinstance(item, dict):
                            # Format 2: [{"domain": "domain.com", "ip": "1.2.3.4"}]
                            if 'domain' in item:
                                parsed_domains.append(item['domain'].lower().strip())
                            elif 'subdomain' in item:
                                parsed_domains.append(item['subdomain'].lower().strip())
                        elif isinstance(item, list) and len(item) > 0:
                            # Format 3: [["domain.com", "1.2.3.4"], ...]
                            parsed_domains.append(str(item[0]).lower().strip())
                    except Exception as e:
                        # Skip invalid items
                        continue

                # Remove duplicates
                domains = list(set(parsed_domains))

                # Filter b·ªè domains qu√° d√†i (>50 chars) v√† kh√¥ng h·ª£p l·ªá
                domains = [d for d in domains if d and len(d) <= 50 and '.' in d]

                print(f"  ‚úì Got {len(domains)} valid domains from C99.NL")
                return domains

        print(f"  ‚úó Could not fetch domains from C99 API")
        return domains


def search_domains_background(keywords, tlds, max_check, min_dr, search_id, mode='keyword', c99_domains=None):
    """Background task ƒë·ªÉ search domains"""
    global search_progress

    try:
        search_progress['status'] = 'running'
        search_progress['message'] = 'ƒêang kh·ªüi t·∫°o...'

        print(f"\n{'='*70}")
        print(f"üîç STARTING SEARCH - ID: {search_id}")
        print(f"{'='*70}")
        print(f"Mode: {mode}")
        print(f"Keywords: {keywords}")
        print(f"TLDs: {tlds}")
        print(f"Max check: {max_check}")
        print(f"Min DR: {min_dr}")
        if mode == 'c99' and c99_domains:
            print(f"C99 Domains: {len(c99_domains)} domains")
        print(f"{'='*70}\n")

        checker = DomainChecker(rapidapi_key=RAPIDAPI_KEY, c99_api_key=C99_API_KEY)

        # Generate domains based on mode
        if mode == 'c99' and c99_domains:
            # C99 Mode: Check H·∫æT domains t·ª´ C99.NL - T√¨m T·∫§T C·∫¢ domains c√≥ traffic
            search_progress['message'] = 'D√πng domains t·ª´ C99.NL...'
            domains_to_check = c99_domains  # Check h·∫øt t·∫•t c·∫£!
            print(f"‚úì Will check ALL {len(domains_to_check)} domains from C99.NL")
            print(f"‚úì Will show ALL domains with DR + Traffic (no limit)")

        else:
            # Keyword Mode: Generate t·ª´ keywords
            search_progress['message'] = 'ƒêang t·∫°o danh s√°ch domains...'
            all_keywords = []
            for kw in keywords:
                variations = checker.generate_keyword_variations(kw.strip().lower(), max_variations=15)
                all_keywords.extend(variations)

            all_keywords = list(dict.fromkeys(all_keywords))[:100]

            all_domains = []
            for kw in all_keywords:
                for tld in tlds:
                    all_domains.append(f"{kw}.{tld}")

            domains_to_check = all_domains[:max_check]

        search_progress['total'] = len(domains_to_check)
        search_progress['message'] = f'S·∫Ω ki·ªÉm tra {len(domains_to_check)} domains...'

        # Check t·ª´ng domain - PARALLEL MODE
        found_domains = []
        found_domains_lock = Lock()  # Thread-safe access
        checked_count = 0
        skipped_registered = 0
        skipped_no_history = 0
        skipped_low_dr = 0
        skipped_not_purchasable = 0

        # H√†m check 1 domain (s·∫Ω ch·∫°y song song)
        def check_single_domain_c99(domain, idx):
            """Check 1 domain trong C99 mode - thread-safe"""
            try:
                # Check DR
                seo_metrics = checker.check_seo_metrics_rapidapi(domain)

                # N·∫øu kh√¥ng c√≥ DR ho·∫∑c kh√¥ng c√≥ Traffic, skip
                if seo_metrics['domain_rating'] == 0:
                    return None

                if seo_metrics['organic_traffic'] == 0:
                    return None

                # CH·ªà L·∫§Y N·∫æU C√ì DR > 0 V√Ä TRAFFIC > 0 ‚≠ê
                if seo_metrics['domain_rating'] > 0 and seo_metrics['organic_traffic'] > 0:
                    # CHECK WHOIS ƒë·ªÉ xem c√≥ available ƒë·ªÉ mua kh√¥ng
                    whois_result = checker.check_domain_availability(domain)
                    is_available = whois_result.get('available', False)

                    if is_available:
                        price_estimate = 'N/A'
                        status = '‚úÖ Available'
                    else:
                        price_estimate = 'Contact Owner'
                        status = 'üîí Registered'

                    # Return domain data
                    return {
                        'domain': domain,
                        'domain_rating': seo_metrics['domain_rating'],
                        'url_rating': seo_metrics['url_rating'],
                        'organic_traffic': seo_metrics['organic_traffic'],
                        'backlinks': seo_metrics['backlinks'],
                        'referring_domains': seo_metrics['referring_domains'],
                        'snapshot_count': 0,
                        'first_archive': 'N/A',
                        'age_years': 0,
                        'available': is_available,
                        'whois_status': status,
                        'price': price_estimate,
                        'purchase_url': f"https://www.namecheap.com/domains/registration/results/?domain={domain}"
                    }
            except Exception as e:
                print(f"Error checking {domain}: {e}")
                return None

        # CHECK SONG SONG v·ªõi ThreadPoolExecutor
        if mode == 'c99':
            print(f"\n{'='*70}")
            print(f"üöÄ PARALLEL MODE: Checking {len(domains_to_check)} domains")
            print(f"   Workers: 20 threads")
            print(f"{'='*70}\n")

            with ThreadPoolExecutor(max_workers=20) as executor:
                # Submit all tasks
                future_to_domain = {
                    executor.submit(check_single_domain_c99, domain, idx): (domain, idx)
                    for idx, domain in enumerate(domains_to_check, 1)
                }

                # Process completed tasks
                for future in as_completed(future_to_domain):
                    domain, idx = future_to_domain[future]

                    # Update progress
                    search_progress['current'] = idx
                    search_progress['current_domain'] = domain
                    search_progress['message'] = f'Check: {idx}/{len(domains_to_check)} | C√≥ traffic: {len(found_domains)}/{len(domains_to_check)}'

                    try:
                        result = future.result()
                        if result:
                            # Thread-safe append
                            with found_domains_lock:
                                found_domains.append(result)
                                search_progress['domains_found'] = found_domains

                            print(f"[{idx}/{len(domains_to_check)}] ‚úÖ {domain} - DR:{result['domain_rating']}, Traffic:{result['organic_traffic']}")
                        else:
                            print(f"[{idx}/{len(domains_to_check)}] ‚è≠Ô∏è  {domain} - Skipped")
                    except Exception as e:
                        print(f"[{idx}/{len(domains_to_check)}] ‚ùå {domain} - Error: {e}")

            print(f"\n{'='*70}")
            print(f"‚úÖ PARALLEL CHECK COMPLETED!")
            print(f"   Checked: {len(domains_to_check)} domains")
            print(f"   Found: {len(found_domains)} domains with traffic")
            print(f"{'='*70}\n")

        # KEYWORD MODE - gi·ªØ nguy√™n sequential
        else:
            for idx, domain in enumerate(domains_to_check, 1):
                search_progress['current'] = idx
                search_progress['current_domain'] = domain
                search_progress['message'] = f'[{idx}/{len(domains_to_check)}] Checking {domain}...'

                try:
                    print(f"\n[{idx}/{len(domains_to_check)}] Checking: {domain}")

                    # KEYWORD MODE: FULL CHECK
                    # 1. WHOIS Check - MORE LENIENT
                    whois_result = checker.check_domain_availability(domain)
                    print(f"  WHOIS: Available={whois_result.get('available')}")

                    # Ch·ªâ skip n·∫øu CH·∫ÆC CH·∫ÆN l√† registered
                    if whois_result.get('available') == False:
                    search_progress['message'] = f'{domain} - Registered ‚úó'
                    skipped_registered += 1
                    print(f"  ‚Üí SKIP: Registered")
                    time.sleep(0.3)
                    continue

                # 2. Wayback Check - LINH HO·∫†T, cho ph√©p m·ªçi domain
                    search_progress['message'] = f'{domain} - Checking history...'
                    wayback_result = checker.check_wayback_history(domain)
                    print(f"  Wayback: Snapshots={wayback_result['snapshot_count']}, Age={wayback_result.get('age_years', 0)}y")

                # Check domain name length
                    domain_name = domain.split('.')[0]
                    is_valuable = len(domain_name) <= 10  # Domain ‚â§10 k√Ω t·ª± = c√≥ gi√° tr·ªã

                # CH·ªà skip domain R·∫§T D√ÄI kh√¥ng c√≥ l·ªãch s·ª≠
                    if wayback_result['snapshot_count'] < 1 and not is_valuable:
                    search_progress['message'] = f'{domain} - No history & qu√° d√†i ‚úó'
                    skipped_no_history += 1
                    print(f"  ‚Üí SKIP: No history + domain qu√° d√†i ({len(domain_name)} chars)")
                    time.sleep(0.3)
                    continue

                # Log info
                    if wayback_result['snapshot_count'] < 1:
                    print(f"  ‚Üí OK: Domain c√≥ gi√° tr·ªã ({len(domain_name)} chars) d√π kh√¥ng c√≥ l·ªãch s·ª≠")
                    else:
                    print(f"  ‚Üí OK: C√≥ l·ªãch s·ª≠ ({wayback_result['snapshot_count']} snapshots)")

                # 3. Estimate DR n·∫øu RapidAPI fail
                    search_progress['message'] = f'{domain} - Checking DR/UR...'
                    seo_metrics = checker.check_seo_metrics_rapidapi(domain)

                # Fallback: Estimate DR t·ª´ snapshots n·∫øu API fail
                    if seo_metrics['domain_rating'] == 0:
                    # Estimate DR C·ª∞C K·ª≤ LINH HO·∫†T - CH·ªà C·∫¶N T√ç DR L√Ä OK
                    # Gi·∫£m y√™u c·∫ßu, tƒÉng ƒëi·ªÉm bonus
                    snapshot_score = min(wayback_result['snapshot_count'] // 3, 60) if wayback_result['snapshot_count'] > 0 else 0
                    age_score = min(wayback_result.get('age_years', 0) * 6, 50)

                    # Bonus KH·ª¶NG cho domain ng·∫Øn
                    domain_name = domain.split('.')[0]
                    length_bonus = 0
                    if len(domain_name) <= 3:
                        length_bonus = 40  # Si√™u ng·∫Øn
                    elif len(domain_name) <= 4:
                        length_bonus = 35
                    elif len(domain_name) <= 5:
                        length_bonus = 28
                    elif len(domain_name) <= 6:
                        length_bonus = 20
                    elif len(domain_name) <= 8:
                        length_bonus = 12
                    elif len(domain_name) <= 10:
                        length_bonus = 6

                    # Base score CAO cho m·ªçi domain available
                    base_score = 10  # TƒÉng t·ª´ 5 l√™n 10

                    estimated_dr = min(base_score + snapshot_score + age_score + length_bonus, 100)

                    seo_metrics['domain_rating'] = estimated_dr
                    seo_metrics['url_rating'] = max(estimated_dr // 2, 5)
                    seo_metrics['organic_traffic'] = wayback_result['snapshot_count'] // 3 if wayback_result['snapshot_count'] > 0 else 0
                    seo_metrics['backlinks'] = wayback_result['snapshot_count'] * 15 if wayback_result['snapshot_count'] > 0 else 0
                    seo_metrics['referring_domains'] = wayback_result['snapshot_count'] * 2 if wayback_result['snapshot_count'] > 0 else 0

                    if wayback_result['snapshot_count'] > 0:
                        print(f"  SEO: DR={seo_metrics['domain_rating']} (Estimate - {wayback_result['snapshot_count']} snap, {wayback_result.get('age_years', 0)}y, len={len(domain_name)})")
                    else:
                        print(f"  SEO: DR={seo_metrics['domain_rating']} (New - len={len(domain_name)} chars)")
                    else:
                    print(f"  SEO: DR={seo_metrics['domain_rating']} (RapidAPI), UR={seo_metrics['url_rating']}, Traffic={seo_metrics['organic_traffic']}")

                    if seo_metrics['domain_rating'] < min_dr:
                    search_progress['message'] = f'{domain} - DR={seo_metrics["domain_rating"]} < {min_dr} ‚úó'
                    skipped_low_dr += 1
                    print(f"  ‚Üí SKIP: DR too low ({seo_metrics['domain_rating']} < {min_dr})")
                    time.sleep(0.3)
                    continue

                # 4. Namecheap Check - OPTIONAL, kh√¥ng b·∫Øt bu·ªôc
                    search_progress['message'] = f'{domain} - Checking price...'
                    price_info = checker.check_registrar_availability(domain)

                # N·∫øu kh√¥ng check ƒë∆∞·ª£c gi√°, v·∫´n ADD v√†o results (gi√° = N/A)
                    if not price_info.get('price'):
                    price_info['price'] = 'N/A'
                    price_info['purchasable'] = True  # Assume c√≥ th·ªÉ mua
                    price_info['url'] = f"https://www.namecheap.com/domains/registration/results/?domain={domain}"

                # FOUND! - Lenient h∆°n nhi·ªÅu
                    checked_count += 1

            except Exception as e:
                search_progress['message'] = f'{domain} - Error: {str(e)[:50]}'
                time.sleep(0.3)
                continue

            # FOUND!
            domain_data = {
                'domain': domain,
                'domain_rating': seo_metrics['domain_rating'],
                'url_rating': seo_metrics['url_rating'],
                'organic_traffic': seo_metrics['organic_traffic'],
                'backlinks': seo_metrics['backlinks'],
                'referring_domains': seo_metrics['referring_domains'],
                'snapshot_count': wayback_result['snapshot_count'],
                'first_archive': wayback_result['first_archive'],
                'age_years': wayback_result['age_years'],
                'price': price_info['price'],
                'purchase_url': price_info['url']
            }

            found_domains.append(domain_data)
            search_progress['domains_found'] = found_domains
            search_progress['message'] = f'‚úì T√¨m th·∫•y: {domain} (DR: {seo_metrics["domain_rating"]})'

            print(f"  ‚úÖ FOUND #{len(found_domains)}: {domain} - DR:{seo_metrics['domain_rating']}, Traffic:{seo_metrics['organic_traffic']}, Price:{price_info['price']}")

            time.sleep(1)

        # Sort results - AVAILABLE + TRAFFIC CAO NH·∫§T L√äN ƒê·∫¶U
        found_domains.sort(key=lambda x: (
            not x.get('available', False),  # Available l√™n ƒë·∫ßu (False < True)
            -x['organic_traffic'],          # Traffic cao l√™n ƒë·∫ßu
            -x['domain_rating'],            # DR cao l√™n ƒë·∫ßu
            -x['backlinks']                 # Backlinks cao l√™n ƒë·∫ßu
        ))

        search_progress['domains_found'] = found_domains
        search_progress['status'] = 'completed'

        # Detailed completion message
        if mode == 'c99':
            stats_msg = f'''‚úì Ho√†n th√†nh! T√¨m th·∫•y {len(found_domains)} domains c√≥ DR

üìä TH·ªêNG K√ä (C99 MODE):
- ƒê√£ check: {len(domains_to_check)} domains t·ª´ C99.NL
- C√≥ DR: {len(found_domains)} domains ({len(found_domains)*100//len(domains_to_check) if len(domains_to_check) > 0 else 0}%)
- Kh√¥ng c√≥ DR: {len(domains_to_check) - len(found_domains)} domains'''
        else:
            stats_msg = f'''‚úì Ho√†n th√†nh! T√¨m th·∫•y {len(found_domains)} domains

üìä TH·ªêNG K√ä (KEYWORD MODE):
- ƒê√£ check: {len(domains_to_check)} domains
- T√¨m ƒë∆∞·ª£c: {len(found_domains)} domains ({len(found_domains)*100//len(domains_to_check) if len(domains_to_check) > 0 else 0}%)

‚ùå B·ªä LO·∫†I:
- Registered: {skipped_registered}
- No history: {skipped_no_history}
- DR < {min_dr}: {skipped_low_dr}'''

        search_progress['message'] = stats_msg

        # Print summary
        print(f"\n{'='*70}")
        print(f"‚úÖ SEARCH COMPLETED - ID: {search_id}")
        print(f"{'='*70}")
        print(f"Checked: {len(domains_to_check)} domains")
        print(f"Found: {len(found_domains)} domains ({len(found_domains)*100//len(domains_to_check) if len(domains_to_check) > 0 else 0}%)")
        print(f"\nSkipped:")
        print(f"  - Registered: {skipped_registered}")
        print(f"  - No history: {skipped_no_history}")
        print(f"  - DR < {min_dr}: {skipped_low_dr}")
        print(f"{'='*70}\n")

        # Export Excel
        if found_domains:
            export_to_excel(found_domains, search_id)
            print(f"‚úÖ Excel exported: results_{search_id}.xlsx\n")

    except Exception as e:
        search_progress['status'] = 'error'
        search_progress['message'] = f'L·ªói: {str(e)}'


def export_to_excel(results: List[Dict], search_id: str):
    """Export k·∫øt qu·∫£ ra Excel"""
    try:
        wb = Workbook()
        ws = wb.active
        ws.title = "Expired Domains"

        # Headers
        headers = ["#", "Domain", "DR", "UR", "Traffic", "Backlinks", "Ref Domains",
                   "Snapshots", "First Archive", "Age (Years)", "Price", "Purchase URL"]

        # Style headers
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        header_font = Font(bold=True, color="FFFFFF", size=11)

        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col)
            cell.value = header
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = Alignment(horizontal='center', vertical='center')

        # Data
        for idx, domain_data in enumerate(results, 1):
            ws.cell(row=idx+1, column=1, value=idx)
            ws.cell(row=idx+1, column=2, value=domain_data['domain'])
            ws.cell(row=idx+1, column=3, value=domain_data['domain_rating'])
            ws.cell(row=idx+1, column=4, value=domain_data['url_rating'])
            ws.cell(row=idx+1, column=5, value=domain_data['organic_traffic'])
            ws.cell(row=idx+1, column=6, value=domain_data['backlinks'])
            ws.cell(row=idx+1, column=7, value=domain_data['referring_domains'])
            ws.cell(row=idx+1, column=8, value=domain_data['snapshot_count'])
            ws.cell(row=idx+1, column=9, value=domain_data['first_archive'])
            ws.cell(row=idx+1, column=10, value=domain_data['age_years'])
            ws.cell(row=idx+1, column=11, value=domain_data['price'])
            ws.cell(row=idx+1, column=12, value=domain_data['purchase_url'])

        # Auto-adjust column widths
        for col in range(1, len(headers) + 1):
            ws.column_dimensions[get_column_letter(col)].width = 15

        # Save
        filename = f"results_{search_id}.xlsx"
        filepath = os.path.join('static', filename)
        os.makedirs('static', exist_ok=True)
        wb.save(filepath)

        search_progress['excel_file'] = filename

    except Exception as e:
        print(f"Error exporting Excel: {e}")


@app.route('/')
def index():
    """Homepage"""
    return render_template('index.html')


@app.route('/api/suggest-keywords', methods=['POST'])
def suggest_keywords():
    """API suggest related keywords"""
    data = request.json
    keyword = data.get('keyword', '').strip()

    if not keyword:
        return jsonify({'error': 'No keyword provided'}), 400

    # Generate related keywords + variations
    result = keyword_gen.generate_all(keyword, max_total=50)

    # Quick suggestions (top 10)
    suggestions = keyword_gen.suggest_keywords(keyword)

    return jsonify({
        'original': keyword,
        'suggestions': suggestions,
        'related': result['related'],
        'variations': result['variations'][:15],
        'all': result['all']
    })


@app.route('/api/search', methods=['POST'])
def start_search():
    """B·∫Øt ƒë·∫ßu search domains"""
    global search_progress

    data = request.json

    mode = data.get('mode', 'keyword')
    c99_domains = data.get('c99_domains', [])
    keywords = [k.strip() for k in data.get('keywords', '').split(',') if k.strip()]
    tlds = data.get('tlds', ['sa.com', 'ru.com', 'in.com', 'za.com', 'br.com'])
    max_check = int(data.get('max_check', 50))
    min_dr = int(data.get('min_dr', 10))

    # Validation based on mode
    if mode == 'c99':
        if not c99_domains:
            return jsonify({'error': 'Vui l√≤ng fetch domains t·ª´ C99.NL tr∆∞·ªõc'}), 400
    else:
        if not keywords:
            return jsonify({'error': 'Vui l√≤ng nh·∫≠p keywords'}), 400

    # Reset progress
    search_id = datetime.now().strftime('%Y%m%d_%H%M%S')
    search_progress = {
        'status': 'starting',
        'current': 0,
        'total': 0,
        'message': 'ƒêang kh·ªüi ƒë·ªông...',
        'domains_found': [],
        'current_domain': '',
        'excel_file': None
    }

    # Start background thread
    thread = Thread(target=search_domains_background, args=(keywords, tlds, max_check, min_dr, search_id, mode, c99_domains))
    thread.daemon = True
    thread.start()

    return jsonify({'status': 'started', 'search_id': search_id, 'mode': mode})


@app.route('/api/progress')
def get_progress():
    """L·∫•y progress hi·ªán t·∫°i"""
    return jsonify(search_progress)


@app.route('/api/fetch-c99-domains', methods=['POST'])
def fetch_c99_domains():
    """API fetch domains t·ª´ C99.NL"""
    data = request.json
    tld = data.get('tld', '').strip()

    if not tld:
        return jsonify({'error': 'No TLD provided'}), 400

    # Initialize checker
    checker = DomainChecker(rapidapi_key=RAPIDAPI_KEY, c99_api_key=C99_API_KEY)

    # Fetch domains
    domains = checker.fetch_domains_from_c99(tld)

    return jsonify({
        'tld': tld,
        'count': len(domains),
        'domains': domains  # Tr·∫£ v·ªÅ H·∫æT t·∫•t c·∫£ domains (kh√¥ng slice)
    })


@app.route('/api/download/<filename>')
def download_file(filename):
    """Download Excel file"""
    filepath = os.path.join('static', filename)
    if os.path.exists(filepath):
        return send_file(filepath, as_attachment=True)
    return jsonify({'error': 'File not found'}), 404


if __name__ == '__main__':
    print("=" * 70)
    print("üåê DOMAIN FINDER WEB APP")
    print("=" * 70)
    print("\n‚úì Server starting...")
    print("‚úì Open browser: http://localhost:5000")
    print("\n" + "=" * 70)
    app.run(debug=True, host='0.0.0.0', port=5000)
